{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "#from model import LeNet5\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[epoch:1, idx: 2000] loss: 2.177\n",
      "[epoch:1, idx: 4000] loss: 1.856\n",
      "[epoch:1, idx: 6000] loss: 1.694\n",
      "[epoch:1, idx: 8000] loss: 1.580\n",
      "[epoch:1, idx:10000] loss: 1.551\n",
      "[epoch:1, idx:12000] loss: 1.476\n",
      "[epoch:2, idx: 2000] loss: 1.416\n",
      "[epoch:2, idx: 4000] loss: 1.406\n",
      "[epoch:2, idx: 6000] loss: 1.356\n",
      "[epoch:2, idx: 8000] loss: 1.299\n",
      "[epoch:2, idx:10000] loss: 1.329\n",
      "[epoch:2, idx:12000] loss: 1.282\n",
      "[epoch:3, idx: 2000] loss: 1.247\n",
      "[epoch:3, idx: 4000] loss: 1.254\n",
      "[epoch:3, idx: 6000] loss: 1.219\n",
      "[epoch:3, idx: 8000] loss: 1.174\n",
      "[epoch:3, idx:10000] loss: 1.203\n",
      "[epoch:3, idx:12000] loss: 1.172\n",
      "[epoch:4, idx: 2000] loss: 1.141\n",
      "[epoch:4, idx: 4000] loss: 1.160\n",
      "[epoch:4, idx: 6000] loss: 1.130\n",
      "[epoch:4, idx: 8000] loss: 1.092\n",
      "[epoch:4, idx:10000] loss: 1.113\n",
      "[epoch:4, idx:12000] loss: 1.088\n",
      "[epoch:5, idx: 2000] loss: 1.059\n",
      "[epoch:5, idx: 4000] loss: 1.089\n",
      "[epoch:5, idx: 6000] loss: 1.055\n",
      "[epoch:5, idx: 8000] loss: 1.018\n",
      "[epoch:5, idx:10000] loss: 1.039\n",
      "[epoch:5, idx:12000] loss: 1.019\n",
      "[epoch:6, idx: 2000] loss: 0.998\n",
      "[epoch:6, idx: 4000] loss: 1.024\n",
      "[epoch:6, idx: 6000] loss: 1.001\n",
      "[epoch:6, idx: 8000] loss: 0.961\n",
      "[epoch:6, idx:10000] loss: 0.976\n",
      "[epoch:6, idx:12000] loss: 0.958\n",
      "[epoch:7, idx: 2000] loss: 0.952\n",
      "[epoch:7, idx: 4000] loss: 0.972\n",
      "[epoch:7, idx: 6000] loss: 0.946\n",
      "[epoch:7, idx: 8000] loss: 0.921\n",
      "[epoch:7, idx:10000] loss: 0.927\n",
      "[epoch:7, idx:12000] loss: 0.914\n",
      "[epoch:8, idx: 2000] loss: 0.905\n",
      "[epoch:8, idx: 4000] loss: 0.941\n",
      "[epoch:8, idx: 6000] loss: 0.908\n",
      "[epoch:8, idx: 8000] loss: 0.870\n",
      "[epoch:8, idx:10000] loss: 0.903\n",
      "[epoch:8, idx:12000] loss: 0.891\n",
      "[epoch:9, idx: 2000] loss: 0.859\n",
      "[epoch:9, idx: 4000] loss: 0.893\n",
      "[epoch:9, idx: 6000] loss: 0.877\n",
      "[epoch:9, idx: 8000] loss: 0.846\n",
      "[epoch:9, idx:10000] loss: 0.872\n",
      "[epoch:9, idx:12000] loss: 0.862\n",
      "[epoch:10, idx: 2000] loss: 0.833\n",
      "[epoch:10, idx: 4000] loss: 0.856\n",
      "[epoch:10, idx: 6000] loss: 0.850\n",
      "[epoch:10, idx: 8000] loss: 0.816\n",
      "[epoch:10, idx:10000] loss: 0.862\n",
      "[epoch:10, idx:12000] loss: 0.830\n",
      "[epoch:11, idx: 2000] loss: 0.825\n",
      "[epoch:11, idx: 4000] loss: 0.841\n",
      "[epoch:11, idx: 6000] loss: 0.829\n",
      "[epoch:11, idx: 8000] loss: 0.806\n",
      "[epoch:11, idx:10000] loss: 0.838\n",
      "[epoch:11, idx:12000] loss: 0.792\n",
      "[epoch:12, idx: 2000] loss: 0.788\n",
      "[epoch:12, idx: 4000] loss: 0.810\n",
      "[epoch:12, idx: 6000] loss: 0.799\n",
      "[epoch:12, idx: 8000] loss: 0.788\n",
      "[epoch:12, idx:10000] loss: 0.807\n",
      "[epoch:12, idx:12000] loss: 0.782\n",
      "[epoch:13, idx: 2000] loss: 0.770\n",
      "[epoch:13, idx: 4000] loss: 0.789\n",
      "[epoch:13, idx: 6000] loss: 0.787\n",
      "[epoch:13, idx: 8000] loss: 0.766\n",
      "[epoch:13, idx:10000] loss: 0.795\n",
      "[epoch:13, idx:12000] loss: 0.788\n",
      "[epoch:14, idx: 2000] loss: 0.760\n",
      "[epoch:14, idx: 4000] loss: 0.781\n",
      "[epoch:14, idx: 6000] loss: 0.773\n",
      "[epoch:14, idx: 8000] loss: 0.755\n",
      "[epoch:14, idx:10000] loss: 0.778\n",
      "[epoch:14, idx:12000] loss: 0.764\n",
      "[epoch:15, idx: 2000] loss: 0.755\n",
      "[epoch:15, idx: 4000] loss: 0.770\n",
      "[epoch:15, idx: 6000] loss: 0.770\n",
      "[epoch:15, idx: 8000] loss: 0.735\n",
      "[epoch:15, idx:10000] loss: 0.780\n",
      "[epoch:15, idx:12000] loss: 0.741\n",
      "[epoch:16, idx: 2000] loss: 0.750\n",
      "[epoch:16, idx: 4000] loss: 0.761\n",
      "[epoch:16, idx: 6000] loss: 0.748\n",
      "[epoch:16, idx: 8000] loss: 0.733\n",
      "[epoch:16, idx:10000] loss: 0.755\n",
      "[epoch:16, idx:12000] loss: 0.758\n",
      "[epoch:17, idx: 2000] loss: 0.732\n",
      "[epoch:17, idx: 4000] loss: 0.749\n",
      "[epoch:17, idx: 6000] loss: 0.755\n",
      "[epoch:17, idx: 8000] loss: 0.728\n",
      "[epoch:17, idx:10000] loss: 0.749\n",
      "[epoch:17, idx:12000] loss: 0.738\n",
      "[epoch:18, idx: 2000] loss: 0.715\n",
      "[epoch:18, idx: 4000] loss: 0.739\n",
      "[epoch:18, idx: 6000] loss: 0.708\n",
      "[epoch:18, idx: 8000] loss: 0.715\n",
      "[epoch:18, idx:10000] loss: 0.746\n",
      "[epoch:18, idx:12000] loss: 0.733\n",
      "[epoch:19, idx: 2000] loss: 0.712\n",
      "[epoch:19, idx: 4000] loss: 0.718\n",
      "[epoch:19, idx: 6000] loss: 0.732\n",
      "[epoch:19, idx: 8000] loss: 0.698\n",
      "[epoch:19, idx:10000] loss: 0.739\n",
      "[epoch:19, idx:12000] loss: 0.727\n",
      "[epoch:20, idx: 2000] loss: 0.711\n",
      "[epoch:20, idx: 4000] loss: 0.711\n",
      "[epoch:20, idx: 6000] loss: 0.713\n",
      "[epoch:20, idx: 8000] loss: 0.716\n",
      "[epoch:20, idx:10000] loss: 0.726\n",
      "[epoch:20, idx:12000] loss: 0.706\n",
      "[epoch:21, idx: 2000] loss: 0.712\n",
      "[epoch:21, idx: 4000] loss: 0.703\n",
      "[epoch:21, idx: 6000] loss: 0.715\n",
      "[epoch:21, idx: 8000] loss: 0.698\n",
      "[epoch:21, idx:10000] loss: 0.723\n",
      "[epoch:21, idx:12000] loss: 0.728\n",
      "[epoch:22, idx: 2000] loss: 0.702\n",
      "[epoch:22, idx: 4000] loss: 0.698\n",
      "[epoch:22, idx: 6000] loss: 0.719\n",
      "[epoch:22, idx: 8000] loss: 0.691\n",
      "[epoch:22, idx:10000] loss: 0.710\n",
      "[epoch:22, idx:12000] loss: 0.719\n",
      "[epoch:23, idx: 2000] loss: 0.693\n",
      "[epoch:23, idx: 4000] loss: 0.709\n",
      "[epoch:23, idx: 6000] loss: 0.708\n",
      "[epoch:23, idx: 8000] loss: 0.696\n",
      "[epoch:23, idx:10000] loss: 0.699\n",
      "[epoch:23, idx:12000] loss: 0.723\n",
      "[epoch:24, idx: 2000] loss: 0.683\n",
      "[epoch:24, idx: 4000] loss: 0.697\n",
      "[epoch:24, idx: 6000] loss: 0.706\n",
      "[epoch:24, idx: 8000] loss: 0.669\n",
      "[epoch:24, idx:10000] loss: 0.704\n",
      "[epoch:24, idx:12000] loss: 0.719\n",
      "[epoch:25, idx: 2000] loss: 0.693\n",
      "[epoch:25, idx: 4000] loss: 0.693\n",
      "[epoch:25, idx: 6000] loss: 0.704\n",
      "[epoch:25, idx: 8000] loss: 0.678\n",
      "[epoch:25, idx:10000] loss: 0.693\n",
      "[epoch:25, idx:12000] loss: 0.735\n",
      "[epoch:26, idx: 2000] loss: 0.669\n",
      "[epoch:26, idx: 4000] loss: 0.686\n",
      "[epoch:26, idx: 6000] loss: 0.686\n",
      "[epoch:26, idx: 8000] loss: 0.675\n",
      "[epoch:26, idx:10000] loss: 0.702\n",
      "[epoch:26, idx:12000] loss: 0.716\n",
      "[epoch:27, idx: 2000] loss: 0.673\n",
      "[epoch:27, idx: 4000] loss: 0.698\n",
      "[epoch:27, idx: 6000] loss: 0.702\n",
      "[epoch:27, idx: 8000] loss: 0.671\n",
      "[epoch:27, idx:10000] loss: 0.725\n",
      "[epoch:27, idx:12000] loss: 0.703\n",
      "[epoch:28, idx: 2000] loss: 0.673\n",
      "[epoch:28, idx: 4000] loss: 0.682\n",
      "[epoch:28, idx: 6000] loss: 0.698\n",
      "[epoch:28, idx: 8000] loss: 0.647\n",
      "[epoch:28, idx:10000] loss: 0.689\n",
      "[epoch:28, idx:12000] loss: 0.724\n",
      "[epoch:29, idx: 2000] loss: 0.668\n",
      "[epoch:29, idx: 4000] loss: 0.701\n",
      "[epoch:29, idx: 6000] loss: 0.686\n",
      "[epoch:29, idx: 8000] loss: 0.664\n",
      "[epoch:29, idx:10000] loss: 0.697\n",
      "[epoch:29, idx:12000] loss: 0.709\n",
      "[epoch:30, idx: 2000] loss: 0.654\n",
      "[epoch:30, idx: 4000] loss: 0.698\n",
      "[epoch:30, idx: 6000] loss: 0.714\n",
      "[epoch:30, idx: 8000] loss: 0.674\n",
      "[epoch:30, idx:10000] loss: 0.719\n",
      "[epoch:30, idx:12000] loss: 0.717\n",
      "[epoch:31, idx: 2000] loss: 0.664\n",
      "[epoch:31, idx: 4000] loss: 0.675\n",
      "[epoch:31, idx: 6000] loss: 0.699\n",
      "[epoch:31, idx: 8000] loss: 0.655\n",
      "[epoch:31, idx:10000] loss: 0.656\n",
      "[epoch:31, idx:12000] loss: 0.698\n",
      "[epoch:32, idx: 2000] loss: 0.668\n",
      "[epoch:32, idx: 4000] loss: 0.688\n",
      "[epoch:32, idx: 6000] loss: 0.689\n",
      "[epoch:32, idx: 8000] loss: 0.668\n",
      "[epoch:32, idx:10000] loss: 0.688\n",
      "[epoch:32, idx:12000] loss: 0.717\n",
      "[epoch:33, idx: 2000] loss: 0.667\n",
      "[epoch:33, idx: 4000] loss: 0.690\n",
      "[epoch:33, idx: 6000] loss: 0.665\n",
      "[epoch:33, idx: 8000] loss: 0.645\n",
      "[epoch:33, idx:10000] loss: 0.701\n",
      "[epoch:33, idx:12000] loss: 0.694\n",
      "[epoch:34, idx: 2000] loss: 0.659\n",
      "[epoch:34, idx: 4000] loss: 0.689\n",
      "[epoch:34, idx: 6000] loss: 0.686\n",
      "[epoch:34, idx: 8000] loss: 0.687\n",
      "[epoch:34, idx:10000] loss: 0.704\n",
      "[epoch:34, idx:12000] loss: 0.704\n",
      "[epoch:35, idx: 2000] loss: 0.647\n",
      "[epoch:35, idx: 4000] loss: 0.678\n",
      "[epoch:35, idx: 6000] loss: 0.682\n",
      "[epoch:35, idx: 8000] loss: 0.682\n",
      "[epoch:35, idx:10000] loss: 0.683\n",
      "[epoch:35, idx:12000] loss: 0.704\n",
      "Finished Training\n",
      "Files already downloaded and verified\n",
      "Accuracy: 57 %\n",
      "Accuracy of plane : 53 %\n",
      "Accuracy of   car : 71 %\n",
      "Accuracy of  bird : 48 %\n",
      "Accuracy of   cat : 41 %\n",
      "Accuracy of  deer : 50 %\n",
      "Accuracy of   dog : 41 %\n",
      "Accuracy of  frog : 73 %\n",
      "Accuracy of horse : 54 %\n",
      "Accuracy of  ship : 73 %\n",
      "Accuracy of truck : 66 %\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#LeNet5模型\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride =2))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride =2))\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU())\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        #nn.Linear()輸入/輸出皆為一維的值, 因此需要將多維的tensor轉成一維\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
    "    \n",
    "    trainSet = torchvision.datasets.CIFAR10(root='./Data', train=True, download=True, transform=transform)\n",
    "\n",
    "    #將訓練集的50000張圖片劃分為12500份, 每份4張圖, 用於mini-batch輸入, shuffle=True表示不同批次的數據使用非固定順序載入\n",
    "    trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=4, shuffle=False)\n",
    "\n",
    "    #10種分類集\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    net = LeNet5().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()   #Loss Function\n",
    "\n",
    "    #使用SGD(隨機梯度下降), 學習率及動量\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    logfile = open('Log/Training.log', 'w')\n",
    "    log_timeflag = time.time()\n",
    "    logfile.write('Train_time: start' + str(log_timeflag) + '\\n')\n",
    "    for epoch in range(35):\n",
    "        running_loss = 0.0\n",
    "        printText = ''\n",
    "        for i, data in enumerate(trainLoader, 0):   #enumerate(sequence, [start=0])\n",
    "            inputs, labels = data                   #data struct = [4(BatchSize)x3x32x32]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            inputs, labels = Variable(inputs), Variable(labels) #轉換inputs, 從tensor轉為variable, variable才具有梯度g\n",
    "            optimizer.zero_grad()                   #初始化Gradient為0\n",
    "\n",
    "            #forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)   #使用CrossEntropy方式計算Loss值\n",
    "            loss.backward()                     #反向傳播求梯度\n",
    "            optimizer.step()                    #使用SGD更新參數\n",
    "\n",
    "            #每2000批數據print avg Loss value\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:\n",
    "                printText = '[epoch:%d, idx:%5d] loss: %.3f' % (epoch+1, i+1, running_loss/2000)\n",
    "                print(printText)\n",
    "                logfile.write(printText+ '\\n')\n",
    "                running_loss = 0.0 \n",
    "print('Finished Training')\n",
    "log_timeflag = time.time()\n",
    "logfile.write('Finished Training: at' + str(log_timeflag))\n",
    "logfile.close()\n",
    "\n",
    "#測試集, 將cifar--batches-py 10000張圖片作為測試數據\n",
    "testSet = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "testLoader = torch.utils.data.DataLoader(testSet, batch_size=4, shuffle=False)\n",
    "correct = 0\n",
    "total = 0\n",
    "logfile = open('Log/Test.log', 'w')\n",
    "log_timeflag = time.time()\n",
    "logfile.write('Test_time: start' + str(log_timeflag) + '\\n')\n",
    "with torch.no_grad():\n",
    "    for data in testLoader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(Variable(images))\n",
    "        value, predicted = torch.max(outputs.data, 1)   #outputs.data size = [4x10]\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "print('Accuracy: %d %%' % (100*correct/total))\n",
    "logfile.write('Accuracy: ' + str(100*correct/total) + ' %\\n')\n",
    "\n",
    "#Output 10 Classes Accuracy\n",
    "class_correct = list(0. for i in range (10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testLoader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100*class_correct[i]/class_total[i]))\n",
    "    logfile.write('Accuracy of ' + str(classes[i]) + ' : ' + str(100*class_correct[i]/class_total[i]) + ' %\\n')\n",
    "logfile.close()\n",
    "torch.save(net, './Model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5522e-03, 2.0346e-08, 9.9823e-01, 9.9067e-07, 1.8949e-04, 1.0315e-08,\n",
      "         9.2958e-06, 2.7830e-08, 1.6225e-05, 1.6152e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([12.6261], device='cuda:0')\n",
      "bird\n"
     ]
    }
   ],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = torch.load('./Model.pth')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    img = cv2.imread('./TestPic/Bird.jpg')                          # 讀圖\n",
    "    img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)   # Resize成Cifar 32x32\n",
    "    cv2.imshow('Resize Pic', img)\n",
    "    cv2.imwrite('./TestPic/Resize_Bird.jpg', img)\n",
    "\n",
    "    trans = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
    "    img = trans(img)\n",
    "    img = img.to(device)\n",
    "    img = img.unsqueeze(0)      #增維, 配合4維Model, 成為[1,1,28,28]\n",
    "    output = model(img)\n",
    "    prob = F.softmax(output, dim=1) #10 classes Percentage\n",
    "    print(prob)\n",
    "    value, predicted = torch.max(output.data, 1)\n",
    "    print(value)\n",
    "    pred_class = classes[predicted.item()]\n",
    "    print(pred_class)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b003d8754f68205f230b91d29752a0899194161977d5c87b83f80e078894fa96"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
